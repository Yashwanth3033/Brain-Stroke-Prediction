
======================================================================
CNN MODEL EVALUATION REPORT
======================================================================

üìÖ Evaluation Date: 2025-11-29 01:38:08
üìä Model Type: Keras/TensorFlow Sequential (CNN/Dense)
üéØ Task: Multi-class Classification

======================================================================
DATASET INFORMATION
======================================================================

Training Samples: 10800
Test Samples: 2685
Number of Features: 18
Number of Classes: 4

Class Distribution (Test Set):
result
0    644
1    698
2    698
3    645

======================================================================
PERFORMANCE METRICS (ON TEST DATA)
======================================================================

OVERALL ACCURACY: 0.9229 (92.29%)

WEIGHTED METRICS (Accounts for Class Imbalance):
  - Precision: 0.9319
  - Recall:    0.9229
  - F1-Score:  0.9234

MACRO METRICS (Equal Weight Per Class):
  - Precision: 0.9336
  - Recall:    0.9230
  - F1-Score:  0.9244

======================================================================
PER-CLASS PERFORMANCE (ON TEST DATA)
======================================================================

              precision    recall  f1-score   support

     Class 0     0.9690    0.9720    0.9705       644
     Class 1     0.9690    0.8496    0.9053       698
     Class 2     0.8153    0.9928    0.8953       698
     Class 3     0.9809    0.8775    0.9264       645

    accuracy                         0.9229      2685
   macro avg     0.9336    0.9230    0.9244      2685
weighted avg     0.9319    0.9229    0.9234      2685


======================================================================
CONFUSION MATRIX (ON TEST DATA)
======================================================================

[[626   6  12   0]
 [  8 593  86  11]
 [  4   1 693   0]
 [  8  12  59 566]]

======================================================================
TOP 10 MOST IMPORTANT FEATURES (FROM SHAP ON TEST DATA)
======================================================================

(Based on Mean Absolute SHAP Value, averaged across all classes)

Empty DataFrame
Columns: [Feature, SHAP_Importance]
Index: []

======================================================================
INTERPRETABILITY METHODS (ON TEST DATA)
======================================================================

‚úÖ LIME (Local Interpretable Model-agnostic Explanations)
   - Generated explanations for 5 test instances
   - Files: cnn_lime_explanation_*.html

‚úÖ SHAP (SHapley Additive exPlanations) using DeepExplainer
   - Computed SHAP values for 100 test instances
   - Generated summary and waterfall plots
   - Files: cnn_shap_*.png

======================================================================
SAVED ARTIFACTS
======================================================================

üìÅ cnn_evaluation_results/
   ‚îú‚îÄ‚îÄ cnn_performance_metrics.csv
   ‚îú‚îÄ‚îÄ cnn_classification_report.csv
   ‚îú‚îÄ‚îÄ cnn_confusion_matrix.png
   ‚îú‚îÄ‚îÄ cnn_confusion_matrix_normalized.png
   ‚îú‚îÄ‚îÄ cnn_roc_curve.png
   ‚îú‚îÄ‚îÄ cnn_lime_explanation_*.html (5 files)
   ‚îú‚îÄ‚îÄ cnn_shap_summary.png
   ‚îú‚îÄ‚îÄ cnn_shap_waterfall_*.png (3 files)
   ‚îú‚îÄ‚îÄ cnn_shap_feature_importance.csv
   ‚îî‚îÄ‚îÄ cnn_evaluation_report.txt (this file)

======================================================================
END OF REPORT
======================================================================
